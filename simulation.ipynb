{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reward matrices\n",
    "baseline_reward_matrix = np.array([[3, 1], [3, 0]])\n",
    "in_group_reward_matrix = np.array([[4, 1], [3, 0]])\n",
    "out_group_reward_matrix = np.array([[7, 1], [5, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agent class and simulation function\n",
    "class Agent:\n",
    "    def __init__(self, group, coop_prob):\n",
    "        self.group = group\n",
    "        self.coop_prob = coop_prob\n",
    "        self.total_reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_pairs(agents):\n",
    "    pairs = []\n",
    "    available_agents = list(agents)  # Convert set to list\n",
    "    \n",
    "    while len(pairs) < len(agents) // 2 and len(available_agents) >= 2:\n",
    "        agent1, agent2 = random.sample(available_agents, 2)\n",
    "        if agent1 != agent2:  # Ensure the same agent isn't paired with itself\n",
    "            pairs.append((agent1, agent2))\n",
    "            available_agents.remove(agent1)\n",
    "            available_agents.remove(agent2)\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "def simulate(agents, reward_matrix, iterations=100, in_group_prob=0.7, out_group_prob=0.3):\n",
    "    for _ in range(iterations):\n",
    "        pairs = select_pairs(agents)\n",
    "        for agent1, agent2 in pairs:\n",
    "            if agent1.group == agent2.group:\n",
    "                current_reward_matrix = in_group_reward_matrix\n",
    "                agent1_cooperates = np.random.rand() < in_group_prob\n",
    "                agent2_cooperates = np.random.rand() < in_group_prob\n",
    "            elif agent1.group == 'none' and agent2.group == 'none':\n",
    "                current_reward_matrix = baseline_reward_matrix\n",
    "                agent1_cooperates = np.random.rand() < 0.5\n",
    "                agent2_cooperates = np.random.rand() < 0.5\n",
    "            else:\n",
    "                current_reward_matrix = out_group_reward_matrix\n",
    "                agent1_cooperates = np.random.rand() < out_group_prob\n",
    "                agent2_cooperates = np.random.rand() < out_group_prob\n",
    "            \n",
    "            if agent1_cooperates and agent2_cooperates:\n",
    "                reward = current_reward_matrix[0, 0]  # both cooperate\n",
    "            elif agent1_cooperates and not agent2_cooperates:\n",
    "                reward = current_reward_matrix[0, 1]  # agent1 cooperates, agent2 does not\n",
    "            elif not agent1_cooperates and agent2_cooperates:\n",
    "                reward = current_reward_matrix[1, 0]  # agent1 does not cooperate, agent2 cooperates\n",
    "            else:\n",
    "                reward = current_reward_matrix[1, 1]  # both do not cooperate\n",
    "            \n",
    "            agent1.total_reward += reward\n",
    "            agent2.total_reward += reward\n",
    "\n",
    "            if agent1.group == agent2.group:\n",
    "                agent1.total_in_group_reward += reward\n",
    "                agent2.total_in_group_reward += reward\n",
    "            else:\n",
    "                agent1.total_out_group_reward += reward\n",
    "                agent2.total_out_group_reward += reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agents for each condition\n",
    "agents_baseline = [Agent(group='none', coop_prob=0.5) for _ in range(30)]\n",
    "agents_compare = [Agent(group='in_group', coop_prob=0.7) for _ in range(15)] + [Agent(group='out_group', coop_prob=0.3) for _ in range(15)]\n",
    "agents_in_group = [Agent(group='in_group', coop_prob=0.7) for _ in range(15)] + [Agent(group='out_group', coop_prob=0.3) for _ in range(15)]\n",
    "agents_out_group = [Agent(group='out_group', coop_prob=0.7) for _ in range(15)] + [Agent(group='in_group', coop_prob=0.3) for _ in range(15)]\n",
    "\n",
    "# Run simulations\n",
    "simulate(agents_baseline, baseline_reward_matrix)\n",
    "simulate(agents_compare, in_group_reward_matrix, in_group_prob=0.7, out_group_prob=0.3)\n",
    "simulate(agents_in_group, in_group_reward_matrix, in_group_prob=0.7, out_group_prob=0.3)\n",
    "simulate(agents_out_group, out_group_reward_matrix, in_group_prob=0.7, out_group_prob=0.3)\n",
    "\n",
    "# Collect results\n",
    "baseline_rewards = [agent.total_reward for agent in agents_baseline]\n",
    "baseline_compare = [agent.total_reward for agent in agents_compare]\n",
    "in_group_rewards = [agent.total_in_group_reward for agent in agents_in_group]\n",
    "out_group_rewards = [agent.total_out_group_reward for agent in agents_out_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Baseline': baseline_rewards,\n",
    "    'Comparison': baseline_compare,\n",
    "    'In-group': in_group_rewards,\n",
    "    'Out-group': out_group_rewards,\n",
    "    'With Identity': [in_group_rewards[i] + out_group_rewards[i] for i in range(len(in_group_rewards))]\n",
    "})\n",
    "\n",
    "# Display DataFrame\n",
    "print(\"Simulation Results\")\n",
    "print(results_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q LEARNING\n",
    "class Agent:\n",
    "    def __init__(self, group, coop_prob=0.5, learning_rate=0.1, discount_factor=0.95):\n",
    "        self.group = group\n",
    "        self.coop_prob = coop_prob\n",
    "        self.total_reward = 0\n",
    "        self.total_in_group_reward = 0\n",
    "        self.total_out_group_reward = 0\n",
    "        self.q_values = {'cooperate': 0, 'not_cooperate': 0}\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.in_group_interactions = 0\n",
    "        self.out_group_interactions = 0\n",
    "\n",
    "    def choose_action(self):\n",
    "        # Choose action based on Q-values\n",
    "        if self.q_values['cooperate'] > self.q_values['not_cooperate']:\n",
    "            return 'cooperate'\n",
    "        elif self.q_values['cooperate'] < self.q_values['not_cooperate']:\n",
    "            return 'not_cooperate'\n",
    "        else:\n",
    "            # If equal, choose randomly based on initial coop_prob\n",
    "            return 'cooperate' if np.random.rand() < self.coop_prob else 'not_cooperate'\n",
    "\n",
    "    def update_q_values(self, action, reward, next_max_q):\n",
    "        # Update Q-values using the Q-learning formula\n",
    "        self.q_values[action] += self.learning_rate * (reward + self.discount_factor * next_max_q - self.q_values[action])\n",
    "\n",
    "def select_pairs(agents):\n",
    "    pairs = []\n",
    "    available_agents = list(agents)\n",
    "\n",
    "    while len(pairs) < len(agents) // 2 and len(available_agents) >= 2:\n",
    "        agent1, agent2 = random.sample(available_agents, 2)\n",
    "        pairs.append((agent1, agent2))\n",
    "        available_agents.remove(agent1)\n",
    "        available_agents.remove(agent2)\n",
    "\n",
    "    return pairs\n",
    "\n",
    "def simulate(agents, reward_matrix, iterations=100, in_group_prob=0.7, out_group_prob=0.3):\n",
    "    for _ in range(iterations):\n",
    "        pairs = select_pairs(agents)\n",
    "        for agent1, agent2 in pairs:\n",
    "            action1 = agent1.choose_action()\n",
    "            action2 = agent2.choose_action()\n",
    "\n",
    "            if agent1.group == agent2.group:\n",
    "                current_reward_matrix = in_group_reward_matrix\n",
    "                agent1.in_group_interactions += 1\n",
    "                agent2.in_group_interactions += 1\n",
    "                reward = current_reward_matrix[0,0]\n",
    "                agent1.total_in_group_reward += reward\n",
    "                agent2.total_in_group_reward += reward\n",
    "            elif agent1.group == 'none' and agent2.group == 'none':\n",
    "                current_reward_matrix = baseline_reward_matrix\n",
    "            else:\n",
    "                current_reward_matrix = out_group_reward_matrix\n",
    "                agent1.out_group_interactions += 1\n",
    "                agent2.out_group_interactions += 1\n",
    "                reward = current_reward_matrix[0, 0]\n",
    "                agent1.total_out_group_reward += reward\n",
    "                agent2.total_out_group_reward += reward\n",
    "\n",
    "            if action1 == 'cooperate' and action2 == 'cooperate':\n",
    "                reward = current_reward_matrix[0, 0]  # both cooperate\n",
    "            elif action1 == 'cooperate' and action2 == 'not_cooperate':\n",
    "                reward = current_reward_matrix[0, 1]  # agent1 cooperates, agent2 does not\n",
    "            elif action1 == 'not_cooperate' and action2 == 'cooperate':\n",
    "                reward = current_reward_matrix[1, 0]  # agent1 does not cooperate, agent2 cooperates\n",
    "            else:\n",
    "                reward = current_reward_matrix[1, 1]  # both do not cooperate\n",
    "\n",
    "            agent1.total_reward += reward\n",
    "            agent2.total_reward += reward\n",
    "\n",
    "            # Update Q-values\n",
    "            next_max_q1 = max(agent1.q_values.values())\n",
    "            next_max_q2 = max(agent2.q_values.values())\n",
    "            agent1.update_q_values(action1, reward, next_max_q1)\n",
    "            agent2.update_q_values(action2, reward, next_max_q2)\n",
    "\n",
    "# Create agents for each condition\n",
    "# agents_07 = [Agent(group='none', coop_prob=0.7) for _ in range(15)]\n",
    "# agents_03 = [Agent(group='none', coop_prob=0.3) for _ in range(15)]\n",
    "\n",
    "agents_baseline = [Agent(group='none', coop_prob=0.5) for _ in range(30)]\n",
    "agents_in_group = [Agent(group='in_group', coop_prob=0.7) for _ in range(15)] + [Agent(group='out_group', coop_prob=0.3) for _ in range(15)]\n",
    "agents_out_group = [Agent(group='out_group', coop_prob=0.7) for _ in range(15)] + [Agent(group='in_group', coop_prob=0.3) for _ in range(15)]\n",
    "\n",
    "# Run simulations\n",
    "simulate(agents_baseline, baseline_reward_matrix)\n",
    "simulate(agents_in_group, in_group_reward_matrix)\n",
    "simulate(agents_out_group, out_group_reward_matrix)\n",
    "\n",
    "# Collect results\n",
    "baseline_rewards = [agent.total_reward for agent in agents_baseline]\n",
    "in_group_rewards = [agent.total_in_group_reward for agent in agents_in_group]\n",
    "out_group_rewards = [agent.total_out_group_reward for agent in agents_out_group]\n",
    "rewards_07_prob_in_group = [agent.total_reward for agent in agents_in_group if agent.coop_prob == 0.7]\n",
    "rewards_03_prob_in_group = [agent.total_reward for agent in agents_in_group if agent.coop_prob == 0.3]\n",
    "rewards_07_prob_out_group = [agent.total_reward for agent in agents_out_group if agent.coop_prob == 0.7]\n",
    "rewards_03_prob_out_group = [agent.total_reward for agent in agents_out_group if agent.coop_prob == 0.3]\n",
    "\n",
    "\n",
    "# Create DataFrame for analysis\n",
    "results_df = pd.DataFrame({\n",
    "    'Baseline': baseline_rewards,\n",
    "    'In-group': in_group_rewards,\n",
    "    'Out-group': out_group_rewards,\n",
    "    'With Identity': [in_group_rewards[i] + out_group_rewards[i] for i in range(len(in_group_rewards))]\n",
    "\n",
    "})\n",
    "\n",
    "# data frame for diff agents\n",
    "df = pd.DataFrame({\n",
    "    '70% Reward In Group': rewards_07_prob_in_group,\n",
    "    '30% Reward In Group': rewards_03_prob_in_group,\n",
    "    '70% Reward Out Group': rewards_07_prob_out_group,\n",
    "    '30% Reward Out Group': rewards_03_prob_out_group\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Simulation Results\")\n",
    "print(results_df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_Identity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
